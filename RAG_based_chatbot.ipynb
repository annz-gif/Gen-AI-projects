{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMeZr4KiKlNZ1Ze+KTlbeq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annz-gif/Gen-AI-projects/blob/main/RAG_based_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZWCQtPm9BgH"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import databutton as db\n",
        "import streamlit as st\n",
        "import openai\n",
        "from brain import get_index_for_pdf\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "import os\n",
        "\n",
        "# Set the title for the Streamlit app\n",
        "st.title(\"RAG enhanced Chatbot\")\n",
        "\n",
        "# Set up the OpenAI API key from databutton secrets\n",
        "os.environ[\"OPENAI_API_KEY\"] = db.secrets.get(\"OPENAI_API_KEY\")\n",
        "openai.api_key = db.secrets.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "\n",
        "# Cached function to create a vectordb for the provided PDF files\n",
        "@st.cache_data\n",
        "def create_vectordb(files, filenames):\n",
        "    # Show a spinner while creating the vectordb\n",
        "    with st.spinner(\"Vector database\"):\n",
        "        vectordb = get_index_for_pdf(\n",
        "            [file.getvalue() for file in files], filenames, openai.api_key\n",
        "        )\n",
        "    return vectordb\n",
        "\n",
        "\n",
        "# Upload PDF files using Streamlit's file uploader\n",
        "pdf_files = st.file_uploader(\"\", type=\"pdf\", accept_multiple_files=True)\n",
        "\n",
        "# If PDF files are uploaded, create the vectordb and store it in the session state\n",
        "if pdf_files:\n",
        "    pdf_file_names = [file.name for file in pdf_files]\n",
        "    st.session_state[\"vectordb\"] = create_vectordb(pdf_files, pdf_file_names)\n",
        "\n",
        "# Define the template for the chatbot prompt\n",
        "prompt_template = \"\"\"\n",
        "    You are a helpful Assistant who answers to users questions based on multiple contexts given to you.\n",
        "\n",
        "    Keep your answer short and to the point.\n",
        "\n",
        "    The evidence are the context of the pdf extract with metadata.\n",
        "\n",
        "    Carefully focus on the metadata specially 'filename' and 'page' whenever answering.\n",
        "\n",
        "    Make sure to add filename and page number at the end of sentence you are citing to.\n",
        "\n",
        "    Reply \"Not applicable\" if text is irrelevant.\n",
        "\n",
        "    The PDF content is:\n",
        "    {pdf_extract}\n",
        "\"\"\"\n",
        "\n",
        "# Get the current prompt from the session state or set a default value\n",
        "prompt = st.session_state.get(\"prompt\", [{\"role\": \"system\", \"content\": \"none\"}])\n",
        "\n",
        "# Display previous chat messages\n",
        "for message in prompt:\n",
        "    if message[\"role\"] != \"system\":\n",
        "        with st.chat_message(message[\"role\"]):\n",
        "            st.write(message[\"content\"])\n",
        "\n",
        "# Get the user's question using Streamlit's chat input\n",
        "question = st.chat_input(\"Ask anything\")\n",
        "\n",
        "# Handle the user's question\n",
        "if question:\n",
        "    vectordb = st.session_state.get(\"vectordb\", None)\n",
        "    if not vectordb:\n",
        "        with st.message(\"assistant\"):\n",
        "            st.write(\"You need to provide a PDF\")\n",
        "            st.stop()\n",
        "\n",
        "    # Search the vectordb for similar content to the user's question\n",
        "    search_results = vectordb.similarity_search(question, k=3)\n",
        "    # search_results\n",
        "    pdf_extract = \"/n \".join([result.page_content for result in search_results])\n",
        "\n",
        "    # Update the prompt with the pdf extract\n",
        "    prompt[0] = {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": prompt_template.format(pdf_extract=pdf_extract),\n",
        "    }\n",
        "\n",
        "    # Add the user's question to the prompt and display it\n",
        "    prompt.append({\"role\": \"user\", \"content\": question})\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.write(question)\n",
        "\n",
        "    # Display an empty assistant message while waiting for the response\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        botmsg = st.empty()\n",
        "\n",
        "    # Call ChatGPT with streaming and display the response as it comes\n",
        "    response = []\n",
        "    result = \"\"\n",
        "    for chunk in openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\", messages=prompt, stream=True\n",
        "    ):\n",
        "        text = chunk.choices[0].get(\"delta\", {}).get(\"content\")\n",
        "        if text is not None:\n",
        "            response.append(text)\n",
        "            result = \"\".join(response).strip()\n",
        "            botmsg.write(result)\n",
        "\n",
        "    # Add the assistant's response to the prompt\n",
        "    prompt.append({\"role\": \"assistant\", \"content\": result})\n",
        "\n",
        "    # Store the updated prompt in the session state\n",
        "    st.session_state[\"prompt\"] = prompt\n",
        "    prompt.append({\"role\": \"assistant\", \"content\": result})\n",
        "\n",
        "    # Store the updated prompt in the session state\n",
        "    st.session_state[\"prompt\"] = prompt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import databutton as db\n",
        "import re\n",
        "from io import BytesIO\n",
        "from typing import Tuple, List\n",
        "import pickle\n",
        "\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores.faiss import FAISS\n",
        "from pypdf import PdfReader\n",
        "import faiss\n",
        "\n",
        "\n",
        "def parse_pdf(file: BytesIO, filename: str) -> Tuple[List[str], str]:\n",
        "    pdf = PdfReader(file)\n",
        "    output = []\n",
        "    for page in pdf.pages:\n",
        "        text = page.extract_text()\n",
        "        text = re.sub(r\"(\\w+)-\\n(\\w+)\", r\"\\1\\2\", text)\n",
        "        text = re.sub(r\"(?<!\\n\\s)\\n(?!\\s\\n)\", \" \", text.strip())\n",
        "        text = re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", text)\n",
        "        output.append(text)\n",
        "    return output, filename\n",
        "\n",
        "\n",
        "def text_to_docs(text: List[str], filename: str) -> List[Document]:\n",
        "    if isinstance(text, str):\n",
        "        text = [text]\n",
        "    page_docs = [Document(page_content=page) for page in text]\n",
        "    for i, doc in enumerate(page_docs):\n",
        "        doc.metadata[\"page\"] = i + 1\n",
        "\n",
        "    doc_chunks = []\n",
        "    for doc in page_docs:\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=4000,\n",
        "            separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
        "            chunk_overlap=0,\n",
        "        )\n",
        "        chunks = text_splitter.split_text(doc.page_content)\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            doc = Document(\n",
        "                page_content=chunk, metadata={\"page\": doc.metadata[\"page\"], \"chunk\": i}\n",
        "            )\n",
        "            doc.metadata[\"source\"] = f\"{doc.metadata['page']}-{doc.metadata['chunk']}\"\n",
        "            doc.metadata[\"filename\"] = filename  # Add filename to metadata\n",
        "            doc_chunks.append(doc)\n",
        "    return doc_chunks\n",
        "\n",
        "\n",
        "def docs_to_index(docs, openai_api_key):\n",
        "    index = FAISS.from_documents(docs, OpenAIEmbeddings(openai_api_key=openai_api_key))\n",
        "    return index\n",
        "\n",
        "\n",
        "def get_index_for_pdf(pdf_files, pdf_names, openai_api_key):\n",
        "    documents = []\n",
        "    for pdf_file, pdf_name in zip(pdf_files, pdf_names):\n",
        "        text, filename = parse_pdf(BytesIO(pdf_file), pdf_name)\n",
        "        documents = documents + text_to_docs(text, filename)\n",
        "    index = docs_to_index(documents, openai_api_key)\n",
        "    return index"
      ],
      "metadata": {
        "id": "qBQI-gFI-Bke"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}